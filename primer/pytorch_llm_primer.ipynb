{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Ks7bnsz9pCUt",
        "OZABsik0rW1O",
        "FEn2i7PsSLQT",
        "bPWIh88vowio"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Install Torch (compatible with book)"
      ],
      "metadata": {
        "id": "Ks7bnsz9pCUt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3ayw1QsnNp3",
        "outputId": "24e33a77-f79c-4bca-99f7-91a8236e35b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n",
            "  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.4.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 triton-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.4.1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__\n",
        "torch.backends.mps.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-2cOIMnqDMn",
        "outputId": "ff4282f4-f223-4019-d096-cb9a2004ab97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Scalars, Tensors, Matrices\n"
      ],
      "metadata": {
        "id": "OZABsik0rW1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor0d = torch.tensor(1)\n",
        "\n",
        "# create a 1D tensor (vector) from a Python list\n",
        "tensor1d = torch.tensor([1, 2, 3])\n",
        "\n",
        "# create a 2D tensor from a nested Python list\n",
        "tensor2d = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "# create a 3D tensor from a nested Python list\n",
        "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "\n",
        "tensor0d, tensor1d, tensor2d, tensor3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzdp5m89rRvc",
        "outputId": "6823047f-f77b-4f46-a0df-ef8cfd3a1787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1),\n",
              " tensor([1, 2, 3]),\n",
              " tensor([[1, 2],\n",
              "         [3, 4]]),\n",
              " tensor([[[1, 2],\n",
              "          [3, 4]],\n",
              " \n",
              "         [[5, 6],\n",
              "          [7, 8]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Size, Reshape, Transpose"
      ],
      "metadata": {
        "id": "j-sEtcMSpHOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the size of an tensor\n",
        "\n",
        "tensor3d.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKYVPqOqr3j5",
        "outputId": "c02220a5-3502-4096-e4bf-4ebd663c2cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshaping it\n",
        "tensor3d.reshape(2,4)\n",
        "tensor3d.view(4,1,2)\n",
        "\n",
        "#transposing\n",
        "tensor_symetric = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "tensor_symetric, torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "\n",
        "#multiplying\n",
        "tensor_to_multiply = torch.tensor([[4,5,6],[7,8,9],[10,11,12]])\n",
        "tensor_symetric.matmul(tensor_to_multiply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6iDnHlGr7oi",
        "outputId": "dcfb6677-6a21-4d18-8526-511ccf53a025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 48,  54,  60],\n",
              "        [111, 126, 141],\n",
              "        [174, 198, 222]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seeing Models as Computation Graphs (autograd)\n",
        "\n",
        "##### Autograd\n",
        "We need to calculate gradients in order to adjust parameters. Autograd calculates gradients.\n",
        "##### Single Layer Nueral Network  (logistic regression classifier)\n",
        "\n"
      ],
      "metadata": {
        "id": "FEn2i7PsSLQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Single Layer Network\n",
        "y is our 'truth'. $x_1$ refers to the inputed value, and $w_1 \\wedge b$ are the parameters that will be updated throughout training.\n",
        "\n",
        "the $z$ equation calculates the raw input, $a$ converts it into a readable probability. $loss$ calculates the difference between the guess and the actual answer. in this case,"
      ],
      "metadata": {
        "id": "KSIE0kUUlmQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y = torch.tensor([1.0])  # true label\n",
        "x1 = torch.tensor([1.1]) # input feature\n",
        "w1 = torch.tensor([2.2]) # weight parameter\n",
        "b = torch.tensor([0.0])  # bias unit\n",
        "\n",
        "z = x1 * w1 + b          # net input\n",
        "a = torch.sigmoid(z)     # activation & output\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "GqZKtpoSsEV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09219e2-a1f9-4f5d-9894-33abab54b005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0852)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatic Differentiation (Autograd)\n",
        "This is what autograd does -- calculates gradients based on loss as calculated above. It back propogates through probability and loss calculations to optimize the parameters.\n"
      ],
      "metadata": {
        "id": "bPWIh88vowio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculates $\\frac{\\partial loss}{\\partial w_1}$ and $\\frac{\\partial loss}{\\partial b}$ (our parameters). notice `requires_grad = True` is needed for the parameters because, originially, we didn't set anything up for backpropogation. `loss.backward()` and the following commands are the most optimal way to get the gradients.\n",
        "\n",
        "[concept video](https://www.youtube.com/watch?v=Ilg3gGewQ5U)"
      ],
      "metadata": {
        "id": "DaKAHPtuxE5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "\n",
        "y = torch.tensor([1.0])\n",
        "x1 = torch.tensor([1.1])\n",
        "w1 = torch.tensor([2.2], requires_grad=True)\n",
        "b = torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "z = x1 * w1 + b\n",
        "a = torch.sigmoid(z)\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "\n",
        "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
        "grad_L_b = grad(loss, b, retain_graph=True)\n",
        "print(grad_L_w1, grad_L_b)\n",
        "# or\n",
        "loss.backward()\n",
        "print(w1.grad, b.grad)\n"
      ],
      "metadata": {
        "id": "vMjx2gyylYdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3214bf2f-01c1-43dc-e2df-84b2bf200e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([-0.0898]),) (tensor([-0.0817]),)\n",
            "tensor([-0.0898]) tensor([-0.0817])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implmenting Network"
      ],
      "metadata": {
        "id": "jIAICRj10mSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All models are build on this based class with these imports. There could be an easier way but this is a good start. Each linear layer is of form $z = x_1w_1 + b$\n",
        "\n",
        "It's a bit confusing, but once we have areguments like `Linear(30,20)`, we start to get weights of $w \\in \\mathbb{R}^{30}$.\n",
        "\n",
        "Each layer is defined by $w \\wedge b $ and is transmitted to `ReLu()` or basically $\\delta$\n"
      ],
      "metadata": {
        "id": "bU0i7pRS0pfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "\n",
        "            # 1st hidden layer\n",
        "            torch.nn.Linear(num_inputs, 30),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # 2nd hidden layer\n",
        "            torch.nn.Linear(30, 20),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # output layer\n",
        "            torch.nn.Linear(20, num_outputs),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "9r1MUC9ywb3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize the model, see the amount of parameters it has (trainable as in it can be backpropogated and gradients can be calculated), and the example see of the first layer's weight.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "a cool fact to notice is that the weights change. that's because at the start, it's a random guess. As it learns, the weights will be tweaked, but at the first instance it's a shot in the dark.\n",
        "\n"
      ],
      "metadata": {
        "id": "ttSmWSx56qrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(50, 3)\n",
        "\n",
        "num_params = sum( #amount of trainable parameters\n",
        "    p.numel() for p in model.parameters() if p.requires_grad\n",
        ")\n",
        "\n",
        "print(model, num_params, model.layers[0].weight.shape)\n",
        "\n",
        "print(model.layers[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca89OKIi6qhE",
        "outputId": "e54cf61f-5939-47b7-f675-d4f2332da2d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ") 2213 torch.Size([30, 50])\n",
            "Parameter containing:\n",
            "tensor([[-0.1246,  0.0794,  0.0908,  ...,  0.0961, -0.0873,  0.0717],\n",
            "        [ 0.0697, -0.0213,  0.1372,  ..., -0.0605,  0.1081, -0.0019],\n",
            "        [ 0.0448, -0.0750, -0.0271,  ...,  0.0299, -0.0588, -0.1273],\n",
            "        ...,\n",
            "        [ 0.0848, -0.0094,  0.1189,  ...,  0.0619,  0.1218, -0.0663],\n",
            "        [-0.0727,  0.0426, -0.0797,  ...,  0.0073, -0.1397,  0.0747],\n",
            "        [-0.0868,  0.1097,  0.0014,  ...,  0.0015, -0.0874,  0.0907]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Taking a Forward Step\n",
        "\n",
        "Here, calling `out = model(X)` performs on forward pass through the system and outputs the last 'guess'\n",
        "\n",
        "Notice that it has that last line, `grad_fn = <AddmmBackward0>`. This is letting us know we set up the model for backpropogation -- if there was a weird situation where this was not necessary, as in we didn't want to train, we wolldn't need to add."
      ],
      "metadata": {
        "id": "4MgQZaA68xpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "X = torch.rand((1, 50))\n",
        "out = model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRHXrrct6yG0",
        "outputId": "c3e927bc-205a-4a6a-bfae-dd71333a0aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1575,  0.2124, -0.1047]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Loaders"
      ],
      "metadata": {
        "id": "PDpZmwoukzdY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code below creates represents two sample datasets, in csv style formatting where each training index maps to the truth index. The purpose of this data class is just have a way to access values in the dataset."
      ],
      "metadata": {
        "id": "ZdWDP1tEnNUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6],\n",
        "])\n",
        "\n",
        "y_test = torch.tensor([0, 1])"
      ],
      "metadata": {
        "id": "GnXeJ_3183kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Dataset({self.features}, {self.labels})\"\n",
        "\n",
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "3FVgCb7snAPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###using the dataloader\n",
        "\n",
        "we establish manual seed because we want to randomize how the batches are fed, and also establish them in the same way each time. another key is that batch size tells how many data to insert at a time, and num workers speeds up the process but at expense of computer resources.\n",
        "\n",
        "finally at the end we iterate through the batch and take a look at each training data that is sent into the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "72hFoUnNo-dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "for idx, (features, labels) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx + 1}: {features}, {labels}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVwinJjFnm_i",
        "outputId": "6d10b389-ab3f-4699-c947-5f1469067376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]), tensor([1, 0])\n",
            "Batch 2: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]), tensor([0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loops"
      ],
      "metadata": {
        "id": "9aLIVsxltSsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 step training example\n",
        "\n",
        "We initialize our custom model with two inputs and two outputs because our data has two features, and in this particular case, we want two output guesses.\n",
        "\n",
        "Notice that we optimize it with a learning rate, arbitrarily ( ill understnd later) and set a number of epochs (also arbitrary).\n",
        "\n",
        "For three passes throughout the nueral network, we set the model into train mode and iterate through the batch of data. Each time, we step forward throughout the network, calculate the loss, and optimize it for the next initilization of the model.\n"
      ],
      "metadata": {
        "id": "pZ6MMBmrybne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "torch.manual_seed(123) #ok\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2) #calls the custom class we made\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5) #optimizer before each loop\n",
        "\n",
        "num_epochs = 3 #how many steps\n",
        "\n",
        "i = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train() # set model in training mode\n",
        "    j = 0\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader): #train loader is the dataset loader\n",
        "\n",
        "\n",
        "        logits = model(features) #forward step\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels) # Loss function for step\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ### LOGGING\n",
        "        print(f\"Epoch: {i+1}/{num_epochs}, Batch: {j+1}/{len(train_loader)}, Train Loss: {loss}\")\n",
        "        j += 1\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z-Wul-trpXV",
        "outputId": "ce13e9ca-9be1-40cc-a691-6c8d420f8b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/3, Batch: 1/2, Train Loss: 0.7487356662750244\n",
            "Epoch: 1/3, Batch: 2/2, Train Loss: 0.6450306177139282\n",
            "Epoch: 2/3, Batch: 1/2, Train Loss: 0.44225579500198364\n",
            "Epoch: 2/3, Batch: 2/2, Train Loss: 0.12562280893325806\n",
            "Epoch: 3/3, Batch: 1/2, Train Loss: 0.026905544102191925\n",
            "Epoch: 3/3, Batch: 2/2, Train Loss: 0.0043272399343550205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions / Evaluating Results\n",
        "here, we make predictions (albeit on the same data) and map them to their assumption (true or false)"
      ],
      "metadata": {
        "id": "fzzBOL1o5CC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_train)\n",
        "\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "probas = torch.softmax(outputs, dim=1)\n",
        "print(probas)\n",
        "\n",
        "predictions = torch.argmax(probas, dim=1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "146szUnB1jS0",
        "outputId": "e3418127-2491-4944-bbae-12199e5a32ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0.9991,     0.0009],\n",
            "        [    0.9982,     0.0018],\n",
            "        [    0.9949,     0.0051],\n",
            "        [    0.0491,     0.9509],\n",
            "        [    0.0307,     0.9693]])\n",
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### compute accuracy template function"
      ],
      "metadata": {
        "id": "YBfEXP1wB89u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model, dataloader):\n",
        "\n",
        "    model = model.eval()\n",
        "    correct = 0.0\n",
        "    total_examples = 0\n",
        "\n",
        "    for idx, (features, labels) in enumerate(dataloader):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(features)\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        compare = labels == predictions\n",
        "        correct += torch.sum(compare)\n",
        "        total_examples += len(compare)\n",
        "\n",
        "    return (correct / total_examples).item()\n",
        "\n",
        "print(compute_accuracy(model, train_loader)) #100%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ7d2DTWAZ4Z",
        "outputId": "aa36be50-75fd-481a-a963-294716de7724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving / Loading"
      ],
      "metadata": {
        "id": "HivG3PjLCae5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "model = NeuralNetwork(2, 2) # needs to match the original model exactly\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULqI_0XSCA18",
        "outputId": "08c7a2bd-649c-43e9-9725-7799d6d6ee64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K8hWHpBgCfOn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}